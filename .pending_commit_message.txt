Progression Phase 7 (Scaffold) – Added ring expansion milestones & keystone heuristic
Progression Phase 7 (Dynamic Expansion Completion)

Enhancements:
- Implemented full dynamic maze ring expansion API `rogue_progression_maze_expand` (procedural outer ring generation, node placement on radial bands, linkage to prior outer ring, full adjacency rebuild & meta refresh). Added helper `rogue_progression_maze_total_rings`.
- Integrated milestone logic + expansion in new unit test `test_progression_phase7_rings` (synthetic minimal maze -> validates milestone ring unlocks, keystone flag invariants, expansion adds >0 rings, ring count increases correctly, no optional/keystone overlap, keystone helper queries correct).
- Upgraded roadmap Phase 7: 7.1 & 7.2 marked Done (scaffold for keystone effects), 7.3 Partial (structural anti-stack guard), 7.5 Done initial; 7.4 pending (visualization layer).
- Cleaned test debug instrumentation; final test emits single success line.

Rationale:
- Provides concrete data structure growth path ahead of visualization & persistence integration.
- Establishes deterministic seed input for future replay & telemetry (seed parameter retained in API).

Follow-ups:
- Persist expanded rings & keystone selection in save snapshot.
- Data-driven keystone definitions + cost/prereq balancing coefficients.
- Integrate anti-stack synergy coefficients in stat aggregation (Phase 9/11) + UI ring layering (7.4).

Summary:
- Implemented Phase 7 groundwork: added ring expansion milestone function `rogue_progression_ring_expansions_unlocked` (+1 ring at level 50 then every 25 levels, capped at +4) to prepare for dynamic outer layer unlocks.
- Extended `progression_maze` meta flags (added bit2 keystone) and introduced constants (`ROGUE_MAZE_FLAG_*`).
- Keystone heuristic: high-degree (>=5) nodes in outer 30% of rings auto-flagged as provisional keystones; optional leaf nodes explicitly excluded.
- Added query helpers: `rogue_progression_maze_is_keystone`, `rogue_progression_maze_keystone_total`.
- Added scaffold test `test_progression_phase7_rings` verifying milestone ring unlock logic, keystone count non-negativity, and optional-keystone mutual exclusion.
- Updated roadmap Phase 7 items 7.1–7.3 & 7.5 to Partial with notes; visualization (7.4) remains unstarted.

Next Steps (future phases):
- Data-driven keystone definition & cost/prerequisite validation.
- Dynamic maze expansion structure allocation & persistence serialization.
- Anti-stack synergy coefficient integration into stat aggregation & passive application layers.
- UI layering & zoom integration (Phase 7.4) once dynamic expansion implemented.

Progression Phase 7 (Anti-Stack & Visualization Completion)

Enhancements:
- Implemented Phase 7.3 anti-stack diminishing returns: keystone unlock now applies per-category coefficient 1/(1+0.15*(k-1)) with heuristic classification (STR/DEX/CRIT -> offense, RES/ARMOR -> defense, else utility). Added category count accessors and widened passive stat accumulator to double to preserve fractional contributions pre-rounding.
- Added unit test `test_progression_phase7_antistack` validating diminished second offense STR increment, defense independence, and keystone count APIs.
- Implemented Phase 7.4 visualization APIs: `rogue_progression_maze_layers` (ring radii), `rogue_progression_maze_project` (polar coords), and `rogue_progression_maze_ascii_overview` (lightweight concentric textual map) supporting dynamic expansions.
- Added unit test `test_progression_phase7_visualization` ensuring layer count matches total rings, radii monotonicity, successful projection, and non-empty ASCII plot.
- Updated roadmap: 7.3 & 7.4 marked Done; documentation (README) reflects anti-stack safeguards & visualization layer support.

Rationale:
- Diminishing returns mitigate runaway stacking of high-impact keystones while preserving first-pick value and categorical diversity.
- Visualization primitives unblock UI/UX Phase 16 integration without binding core logic to rendering libraries.

Follow-ups:
- Persist keystone category counts & expanded ring layout in snapshot serialization (Phase 12 alignment).
- Replace heuristic keystone classification with data-driven tags; expose JSON-driven overrides.
- Integrate coefficient application into future composite stat cache (Phases 9 & 11) for multiplicative vs additive ordering validation.

Summary:
- Phase 7 core now feature-complete (7.1–7.5 implemented/tested) pending future data-driven refinement & UI polish.
Progression Phase 8 (Perpetual Scaling Layer)

Implemented continuous micro-node progression system with sublinear aggregate scaling.

Details:
- Added module `progression_perpetual.[ch]` providing APIs: allowance (`rogue_perpetual_micro_nodes_allowed`), spend guard (`rogue_perpetual_spend_node`), raw power (diminishing per-node), level scalar (smooth asymptote), global coefficient tuning, inflation guard adjust, and effective power aggregation.
- Diminishing formula: per-node contribution BASE/(1+CURV*i) (BASE=0.015, CURV=0.07) ensuring decreasing marginal returns.
- Level scalar: (1-exp(-L/140))^0.80 producing soft early acceleration, tapering mid-late; combined with node diminishing keeps effective exponent <0.65 beyond level 200 (roadmap metric).
- Inflation guard: `rogue_perpetual_inflation_adjust(delta)` clamps resulting coefficient inside [0.85,1.15] for stable balance tuning loops.
- Unit test `test_progression_phase8_perpetual` validates: allowance pacing, spend cap enforcement, diminishing increments (first vs last), sublinear growth (power ratio level200/level100 < 2x).
- Roadmap Phase 8 items 8.1–8.5 marked Done; README updated with changelog entry.

Rationale:
- Provides endless but controlled progression track post primary maze & mastery layers, avoiding hard caps while guarding against runaway inflation.

Follow-ups:
- Integrate effective power into analytics power index (Phase 13) & difficulty scaler (Phase 14) inputs.
- Persist micro-node spend count (Phase 12) with versioned header.
- Telemetry feedback loop hooking TTK distributions to inflation adjust API.

Progression Phase 9 (Synergy & Caps)

Enhancements:
- Added `progression_synergy.[ch]` implementing unified layered damage aggregation helper (`rogue_progression_layered_damage`) applying canonical order Equipment -> Passives -> Mastery -> Micro (perpetual) over a base flat value.
- Implemented crit chance soft cap (60%) with diminishing smoothing (softness=0.55) and hard cap (95%) via `rogue_progression_final_crit_chance`.
- Implemented cooldown reduction soft cap (50%) with diminishing curve (softness=0.60) and hard cap (70%) via `rogue_progression_final_cdr`.
- Introduced tag mask derivation bridging weapon infusion (fire/frost/arcane) to skill tag bits (`rogue_progression_synergy_tag_mask`).
- Added conditional fire synergy helper (`rogue_progression_synergy_fire_bonus`) returning passive bonus only when FIRE tag present (scaffold for future multi-tag conditionals).
- New unit test `test_progression_phase9_synergy` validates: layered damage multiplicative math (~1.4786x expected), attribute aggregation sum, crit & CDR cap clamps (pre & post soft cap), tag mask mapping, and conditional fire bonus gating.
- Roadmap Phase 9 items 9.1–9.5 updated to Done with implementation notes. README changelog updated accordingly.

Rationale:
- Establishes explicit, audited ordering preventing ambiguous stacking exploits and provides early enforcement of key stat ceilings prior to buff/debuff layer integration (Phase 10).
- Tag bridge lays groundwork for data-driven synergy expansions (equipment affix & passive conditional interplay) without entangling core effect DSL yet.

Follow-ups:
- Extend tag mask to include future affix-origin tags & skill-learned tags beyond weapon infusion (data registry). 
- Integrate crit/CDr clamps into final combat stat snapshot hashing for anti-tamper verification (Phase 15).
- Expand synergy helpers for multi-element composites and additive vs multiplicative classification audit.

Progression Phase 10 (Buff/Debuff Integration)

Enhancements:
- Extended stat cache to incorporate buff layer (currently strength exemplar) after passives for proper ordering.
- Added stacking rule enum (unique, refresh, extend, add) with logic in `rogue_buffs_apply` including magnitude & duration semantics.
- Introduced per-buff snapshot flag (retains applied magnitude independent of subsequent base stat changes; groundwork for future dynamic vs snapshot distinction on other stats).
- Implemented anti-oscillation dampening via configurable minimum reapply interval (`rogue_buffs_set_dampening`). Early reapplications inside window rejected.
- Added helpers: `rogue_buffs_strength_bonus` and updated `stat_cache` to fetch buff layer; global interval default 50ms.
- New unit test `test_progression_phase10_buffs` validates stacking behaviors, additive strength aggregation into cache, and dampening gating.
- Roadmap Phase 10 entries 10.1–10.5 marked Done; README updated with changelog entry.

Rationale:
- Establishes systematic timed effect layer ahead of broader buff/debuff catalog; prevents visual/stat flicker and clarifies deterministic aggregation sequence.

Follow-ups:
- Extend buff system to support additional attribute/stat types and negative debuffs with separate accessor categories.
- Implement snapshot vs dynamic application in combat formulas (e.g., snapshotting at cast start vs real-time tick updates) once skill effect layer (Phase 10.2 extended) requires.
- Persistence & hashing of active buffs (Phase 12/15) for anti-tamper verification.

Progression Phase 11 (Performance & Caching – Initial Dirty Flags & Size Guard)

Enhancements:
- Implemented incremental dirty flag system in `stat_cache` with bitmask (attr=1, passive=2, buff=4, equipment=8). `rogue_stat_cache_mark_*` APIs now selectively flag layers; full mark sets 0xFFFFFFFF.
- Added instrumentation counters: `recompute_count` (total cache rebuilds) and `heavy_passive_recompute_count` (expensive passive layer recomputes) to support future micro-bench & latency tracking.
- Integrated selective recompute path: buff-only dirties avoid re-running passive aggregation; passive dirty increments heavy counter.
- Added size/accessor helpers: `rogue_stat_cache_sizeof` & `rogue_stat_cache_heavy_passive_recompute_count` for tests & telemetry.
- New unit test `test_progression_phase11_cache` validates: buff dirty does not trigger passive recompute, passive dirty does; struct size < 2 KB (well below <64 KB target) establishing early guardrail.
- Roadmap updated: 11.1 Done, 11.4 Done, 11.5 Partial (initial correctness test) with notes; remaining 11.2 (SoA passives), 11.3 (micro-bench), further latency metrics pending.

Rationale:
- Lays groundwork for future performance optimization by preventing redundant passive effect aggregation when only transient layers (buffs) change.
- Early size tracking ensures hot cache remains comfortably within L1/L2 friendly bounds before adding more fields in subsequent phases.

Follow-ups:
- Implement SoA layout for passive effect accumulators (Phase 11.2) to improve data locality & vectorization potential.
- Add micro-benchmark harness measuring recompute cost under synthetic 200-node passive unlock scenario (Phase 11.3) with timing histograms.
- Expand tests to assert recompute counter deltas under mixed dirty sequences & integrate simple time threshold assertions (feature-gated to avoid flakiness).

Progression Phase 11 (Continued – SoA & Micro-Benchmark)

Enhancements:
- Implemented Phase 11.2 SoA mirrors for passive effects: arrays `g_effect_stat_ids[]` and `g_effect_deltas[]` populated during DSL parse; unlock application loop now iterates SoA for improved spatial locality (preparing future SIMD / batching).
- Added Phase 11.3 micro-benchmark test `test_progression_phase11_bench` executing 4k iterations comparing full dirty vs buff-only dirty recompute paths; asserts >5% speed differential unless total time extremely small (<5ms guard) to avoid flaky failures on fast hosts.
- Updated roadmap: 11.2 and 11.3 marked Done; 11.5 Partial adjusted to reflect added coverage (latency ratio + dirty avoidance). README pending next aggregation update.

Rationale:
- SoA structure reduces cache line thrash when iterating many passive effects and sets stage for vectorized accumulation or per-stat reduction passes.
- Early benchmark provides regression signal for future optimization phases (ensuring dirty path remains materially cheaper as layers expand).

Follow-ups:
- Integrate re-spec replay stale-cache test (mark passives dirty, reapply DSL, ensure counters increment & fingerprints differ appropriately).
- Collect percentile timing (P50/P95) using high-res timer (platform abstraction) and export metrics for CI threshold gating.

Update: Added Phase 11.5 re-spec stale cache test `test_progression_phase11_respec` confirming stat cache fingerprint changes after passive DSL reload + unlock replay (guards against stale passive layer after re-spec). Roadmap 11.5 note updated (percentile latency still pending).

Progression Phase 11 (Passive Layer Integration & Re-spec Completion)

Enhancements:
- Integrated passive stat totals into stat cache layering: added passive_* fields (primary attributes) between affix and buff layers; totals now include passive contributions.
- Selective recompute: passive layer queried only when passive dirty bit set; buff-only dirties remain lightweight.
- Re-spec stale cache integrity: fingerprint now changes on passive DSL reload due to passive layer inclusion; `test_progression_phase11_respec` passes.
- Roadmap Phase 11.5 updated to Done (functional correctness). P95 latency metric explicitly deferred to future perf tooling phase.

Rationale:
- Prevents stale combat stat snapshots after talent re-spec ensuring downstream analytics & anti-tamper hashes remain sensitive to passive graph changes.
- Maintains performance focus by avoiding unnecessary passive queries on frequent buff updates.

Follow-ups:
- Add high-resolution timing sampler (QueryPerformanceCounter / std::chrono fallback) and percentile aggregation for future CI perf gating.

Progression Phase 12 (Persistence & Migration – Initial Header & Legacy Migration)

Enhancements:
- Added new module `progression_persist.[ch]` implementing versioned progression save header (current version V2). V1 header supported fields: version, level, total XP, attributes (str/dex/vit/int), spent points (stored in field `unspent_pts` for backward compatibility naming), respec tokens, attribute journal hash, passive journal hash, passive entry count (placeholder, currently zero).
- V2 header extends V1 with stat registry fingerprint (`stat_registry_fp`) and maze node count placeholder (`maze_node_count`) to enable future migration flagging when stat taxonomy or maze topology evolves.
- Implemented write/read APIs producing/consuming the compact header and computing a deterministic chain hash (fold64 over version, level, xp_total, stat_registry_fp (0 for V1), passive_journal_hash) to integrate with broader persistence integrity chain semantics.
- Added migration flag tracking: currently sets `ROGUE_PROG_MIG_STAT_REG_CHANGED` when loaded stat registry fingerprint (V2) or passive journal hash (V1 legacy comparison path) differs from runtime, establishing early hook for future stat/talent migrations.
- Registered progression persistence as save component id=27 (separate from existing core save sections) via save manager interface (write_fn/read_fn with size parameter compatibility shim).
- Introduced global singleton `g_attr_state` (moved from purely local usage) to expose attribute layer snapshot for persistence without threading through call chains.
- Created unit test `test_progression_phase12_persistence` validating: (1) current version roundtrip (level, xp, attributes, spent points, respec tokens, journal hash) with identical chain hash pre/post load, (2) legacy V1 buffer load path reconstructing state and optionally setting migration flag, ensuring backward compatibility.
- Updated roadmap Phase 12: item 12.1 marked Done, 12.5 Partial (only header/migration basics covered; talent bitset, re-spec journal, additional migration invariants pending in subsequent slices).

Rationale:
- Establishes minimal but forward-compatible progression snapshot enabling upcoming serialization of talents, ascendancy/maze unlocks, micro-node spends, and mastery expansions without rewriting early persistence scaffolding.
- Early chain hash inclusion facilitates anti-tamper & analytics correlation once additional progression components are serialized.

Follow-ups:
- Serialize passive unlock journal entries (node_id,timestamp) with bounded count encoding and replay validation on load.
- Add talent / ascendancy sparse encoding (bitset for compact early ranges; varint sparse list for high ID space) and integrate into header or trailing section with size prefix.
- Persist mastery ring points & continuous micro-node spend count (Phase 8 linkage) and compute composite progression fingerprint.
- Implement re-spec journal hash chaining & migration path applying diffs to reconcile removed/added nodes.
- Extend tests to cover: (a) tampered header detection (invalid version, truncated), (b) stat registry fingerprint mismatch flagging, (c) simulated addition of new stat IDs with migration flag assertion.

Testing:
- New unit test passes (roundtrip + legacy). Chain hash parity verified after load by recomputing identical sequence of folds in read path.
- Build integrated under SDL2 (SDL requirement still enforced globally) with no additional warnings (save component read_fn signature matched size parameter contract).

Summary:
- Delivered initial progression persistence slice with forward-compatible header & migration flagging plus test coverage, unblocking serialization of richer progression state in subsequent Phase 12 tasks.

